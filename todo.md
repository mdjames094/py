# OBJECTIVE(s)
## Define different methods for Weight initialisation
### Xavier [ok]
    - Sigmoid and Tanh activation functions
    - W ~ N(0; 2 / (Nin + Nout))
    - Uniform distribution may be used to
### He [ok] 
    - ReLU activation function
    - W ~ N(0; 2 / Nin)
## Define differents methods for learning rate
    - Exponential decay [ok]
    - Time-based decay [ok]
    - Step-based decay [ok]
## Implement regularization (weights)
    - L2 regularisation [ok]
## Refactoring
    - First step